{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df=pd.read_pickle('./data/train_df.pickle')\n",
    "#test_df=pd.read_pickle('./data/test_df.pickle')\n",
    "train_df=pd.read_pickle('./data/train_df_nopunc.pickle')\n",
    "test_df=pd.read_pickle('./data/test_df_nopunc.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 3600000/3600000 [00:28<00:00, 127776.88it/s]\n"
     ]
    }
   ],
   "source": [
    "comment_lengths=list()\n",
    "comment_list=train_df['text'].tolist()\n",
    "for i in tqdm(range(len(comment_list))):\n",
    "    comment=comment_list[i]\n",
    "    temp1=len(comment.split())\n",
    "    comment_lengths.append(temp1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 400000/400000 [00:03<00:00, 128981.31it/s]\n"
     ]
    }
   ],
   "source": [
    "comment_lengths_test=list()\n",
    "comment_list_test=test_df['text'].tolist()\n",
    "for i in tqdm(range(len(comment_list_test))):\n",
    "    comment=comment_list_test[i]\n",
    "    temp1=len(comment.split())\n",
    "    comment_lengths_test.append(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_simple_from_tf=np.load('./data/word2vec_simple.npz')\n",
    "word2vec_simple_from_tf=np.load('./data/GLOVE_1p9M.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=word2vec_simple_from_tf['arr_0']\n",
    "word_dict=word2vec_simple_from_tf['arr_1'].tolist()\n",
    "reverse_dict=word2vec_simple_from_tf['arr_2'].tolist()\n",
    "embedding_size=embeddings.shape[1]\n",
    "comment_vector_size=embedding_size*max(comment_lengths)\n",
    "num_comments=len(comment_list)\n",
    "train_labels=(train_df['label']).tolist()\n",
    "n_embeddings,d_embeddings=embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 3600000/3600000 [03:46<00:00, 15905.50it/s]\n"
     ]
    }
   ],
   "source": [
    "comments_with_word_indices=np.zeros(shape=(num_comments,max(comment_lengths)),dtype='int32')\n",
    "for i in tqdm(range(len(comment_list))):\n",
    "    comment=comment_list[i]\n",
    "    comment_words=comment.split()\n",
    "    for j,word in enumerate(comment_words):\n",
    "        comments_with_word_indices[i,j]=word_dict.get(word,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size):\n",
    "    batch_indices=random.sample(range(num_comments),batch_size)\n",
    "    batch_inputs=comments_with_word_indices[batch_indices,:]\n",
    "    batch_labels=np.reshape(np.asarray([train_labels[idx] for idx in batch_indices])-1,(batch_size,1))\n",
    "    return batch_inputs, batch_labels, batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "90\n",
      "[1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "a=generate_batch(2) \n",
    "b=a[0][0]\n",
    "index1=a[2][0]\n",
    "c=[o for o in b if o!=0]\n",
    "print(len(c))\n",
    "print(len(comment_list[index1].split()))\n",
    "label1=a[1][0]\n",
    "print(label1)\n",
    "print(train_df['label'][index1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating test dataset\n",
    "num_comments_test=len(comment_list_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/CNN4_GLOVE.ckpt\n",
      "initialized\n",
      "Step: 5 ,Average loss in 5 steps: 0.382 ,batch time: 0.00 ,Run time: 10.53 Batch Accuracy: 81.25 Valid accuracy: 86.80\n",
      "Step: 10 ,Average loss in 5 steps: 0.342 ,batch time: 0.00 ,Run time: 8.46 Batch Accuracy: 81.25 Valid accuracy: 86.80\n",
      "Step: 15 ,Average loss in 5 steps: 0.318 ,batch time: 0.00 ,Run time: 8.51 Batch Accuracy: 81.25 Valid accuracy: 85.80\n",
      "Step: 20 ,Average loss in 5 steps: 0.354 ,batch time: 0.00 ,Run time: 8.62 Batch Accuracy: 87.50 Valid accuracy: 86.60\n",
      "Step: 25 ,Average loss in 5 steps: 0.344 ,batch time: 0.00 ,Run time: 8.64 Batch Accuracy: 84.38 Valid accuracy: 88.00\n",
      "Step: 30 ,Average loss in 5 steps: 0.399 ,batch time: 0.00 ,Run time: 9.06 Batch Accuracy: 84.38 Valid accuracy: 85.40\n",
      "Step: 35 ,Average loss in 5 steps: 0.287 ,batch time: 0.00 ,Run time: 9.36 Batch Accuracy: 95.31 Valid accuracy: 85.40\n",
      "Step: 40 ,Average loss in 5 steps: 0.321 ,batch time: 0.00 ,Run time: 8.87 Batch Accuracy: 92.19 Valid accuracy: 83.80\n",
      "Step: 45 ,Average loss in 5 steps: 0.384 ,batch time: 0.00 ,Run time: 9.47 Batch Accuracy: 92.19 Valid accuracy: 85.20\n",
      "Step: 50 ,Average loss in 5 steps: 0.427 ,batch time: 0.00 ,Run time: 9.72 Batch Accuracy: 82.81 Valid accuracy: 86.60\n",
      "Step: 55 ,Average loss in 5 steps: 0.352 ,batch time: 0.00 ,Run time: 9.10 Batch Accuracy: 85.94 Valid accuracy: 86.80\n",
      "Step: 60 ,Average loss in 5 steps: 0.387 ,batch time: 0.00 ,Run time: 9.02 Batch Accuracy: 87.50 Valid accuracy: 85.80\n",
      "Step: 65 ,Average loss in 5 steps: 0.365 ,batch time: 0.00 ,Run time: 9.25 Batch Accuracy: 89.06 Valid accuracy: 85.40\n",
      "Step: 70 ,Average loss in 5 steps: 0.287 ,batch time: 0.00 ,Run time: 9.29 Batch Accuracy: 95.31 Valid accuracy: 87.80\n",
      "Step: 75 ,Average loss in 5 steps: 0.374 ,batch time: 0.00 ,Run time: 9.25 Batch Accuracy: 82.81 Valid accuracy: 86.60\n",
      "Step: 80 ,Average loss in 5 steps: 0.275 ,batch time: 0.00 ,Run time: 8.71 Batch Accuracy: 82.81 Valid accuracy: 86.20\n",
      "Step: 85 ,Average loss in 5 steps: 0.304 ,batch time: 0.00 ,Run time: 9.23 Batch Accuracy: 87.50 Valid accuracy: 86.00\n",
      "Step: 90 ,Average loss in 5 steps: 0.394 ,batch time: 0.00 ,Run time: 8.77 Batch Accuracy: 81.25 Valid accuracy: 85.00\n",
      "Step: 95 ,Average loss in 5 steps: 0.424 ,batch time: 0.00 ,Run time: 9.23 Batch Accuracy: 92.19 Valid accuracy: 85.80\n",
      "Step: 100 ,Average loss in 5 steps: 0.324 ,batch time: 0.00 ,Run time: 8.75 Batch Accuracy: 84.38 Valid accuracy: 85.40\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_steps=101\n",
    "batch_size=64\n",
    "graph=tf.Graph()\n",
    "batch_timing=0\n",
    "run_timing=0\n",
    "num_filters=100\n",
    "kernel_size=2\n",
    "restore_sess=1\n",
    "test_batch_size=int(num_comments_test/100)\n",
    "validation_batch_size=500\n",
    "\n",
    "#model_name=\"./ckpt/LR_word2vec.ckpt\"\n",
    "model_name=\"./ckpt/CNN4_GLOVE.ckpt\"\n",
    "steps_display=min(int((num_steps-1)/20),1000)\n",
    "with graph.as_default():\n",
    "    inputs=tf.placeholder(tf.int32, shape=(batch_size,max(comment_lengths)))\n",
    "    test_inputs=tf.placeholder(tf.int32, shape=(test_batch_size,max(comment_lengths)))\n",
    "    validation_inputs=tf.placeholder(tf.int32, shape=(validation_batch_size,max(comment_lengths)))\n",
    "    labels=tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "    embedding_matrix=tf.placeholder(tf.float32, shape=(n_embeddings,d_embeddings))\n",
    "    layer1_weights=tf.Variable(tf.truncated_normal([kernel_size,d_embeddings,num_filters],stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.ones([num_filters]))\n",
    "    hidden_weights=tf.Variable(tf.truncated_normal([max(comment_lengths)*num_filters,1],stddev=0.1))\n",
    "    hidden_biases=tf.Variable(tf.constant(1.0, shape=[1]))\n",
    "    \n",
    "    def model_graph(data):\n",
    "        batch_embeddings=tf.nn.embedding_lookup(embedding_matrix,data)\n",
    "        conv1=tf.nn.conv1d(batch_embeddings,layer1_weights,stride=1,padding='SAME')\n",
    "        conv1=tf.nn.relu(conv1)\n",
    "        shape=conv1.get_shape().as_list()\n",
    "        conv1=tf.reshape(conv1,[shape[0],shape[1],shape[2],1])\n",
    "        pool1=tf.nn.max_pool(conv1,[1,1,num_filters,1],strides=[1,1,1,1],padding='SAME')\n",
    "        shape=pool1.get_shape().as_list()\n",
    "        flat1=tf.reshape(pool1,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        flat1=tf.nn.dropout(flat1,keep_prob=0.5)\n",
    "        y_pred_model=tf.matmul(flat1,hidden_weights)+hidden_biases\n",
    "        return y_pred_model\n",
    "    \n",
    "    y_pred=model_graph(inputs)\n",
    "    y_pred_test=model_graph(test_inputs)\n",
    "    y_pred_validation=model_graph(validation_inputs)\n",
    "    test_predictions=tf.round(tf.sigmoid(y_pred_test))\n",
    "    validation_predictions=tf.round(tf.sigmoid(y_pred_validation))\n",
    "    train_predictions=tf.round(tf.sigmoid(y_pred))\n",
    "    x_entropy=tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred,labels=labels)\n",
    "    loss =tf.reduce_mean(x_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver=tf.train.Saver()\n",
    "\n",
    "sess=tf.Session(graph=graph)\n",
    "with sess.as_default():\n",
    "    init.run()\n",
    "    if restore_sess==1:\n",
    "        try:\n",
    "            saver.restore(sess,model_name)\n",
    "        except:\n",
    "            print('Unexpected Error: model cannot be restored')\n",
    "    print('initialized')\n",
    "    loss_val_sum=0\n",
    "    for i in range(num_steps):\n",
    "        time1=time.time()\n",
    "        batch_inputs,batch_labels,_=generate_batch(batch_size)\n",
    "        time2=time.time()\n",
    "        feed_dict={inputs:batch_inputs,labels:batch_labels,embedding_matrix:embeddings}\n",
    "        _,loss_val,train_preds=sess.run([optimizer,loss,train_predictions],feed_dict=feed_dict)\n",
    "        time3=time.time()\n",
    "        batch_timing += time2-time1\n",
    "        run_timing += time3-time2\n",
    "        loss_val_sum += loss_val\n",
    "        if i % steps_display==0 and i!=0:\n",
    "            validation_batch,validation_labels,_=generate_batch(validation_batch_size)\n",
    "            #validation_batch=batch_inputs\n",
    "            #validation_labels=batch_labels\n",
    "            validation_preds=sess.run(validation_predictions,\n",
    "                                      feed_dict={validation_inputs:validation_batch,embedding_matrix:embeddings})            \n",
    "            print('Step:',i,\n",
    "                  ',Average loss in',steps_display, 'steps:',\"{0:.3f}\".format(loss_val_sum/steps_display),',batch time:'\n",
    "                  ,\"{0:.2f}\".format(batch_timing),',Run time:',\"{0:.2f}\".format(run_timing)\n",
    "                  ,'Batch Accuracy:', \"{:4.2f}\".format(100*accuracy_score(batch_labels,train_preds))\n",
    "                  ,'Valid accuracy:',\"{:4.2f}\".format(100*accuracy_score(validation_labels,validation_preds)))\n",
    "            batch_timing=0\n",
    "            run_timing=0\n",
    "            loss_val_sum=0\n",
    "    try:\n",
    "        saver.save(sess,model_name)\n",
    "        print('Model saved!')\n",
    "    except:\n",
    "        print('Model could not be saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del comments_with_word_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                               | 0/400000 [00:00<?, ?it/s]\n",
      "  0%|                                     | 25/400000 [00:00<26:55, 247.52it/s]\n",
      "  0%|                                    | 176/400000 [00:00<07:40, 867.83it/s]\n",
      "  0%|                                  | 1078/400000 [00:00<01:52, 3559.98it/s]\n",
      "  1%|▏                                 | 2285/400000 [00:00<01:10, 5672.56it/s]\n",
      "  1%|▎                                 | 3548/400000 [00:00<00:56, 7061.81it/s]\n",
      "  1%|▍                                 | 4728/400000 [00:00<00:51, 7675.05it/s]\n",
      "  1%|▌                                 | 5999/400000 [00:00<00:47, 8371.21it/s]\n",
      "  2%|▋                                 | 7396/400000 [00:00<00:44, 8891.31it/s]\n",
      "  2%|▋                                 | 8769/400000 [00:00<00:41, 9404.52it/s]\n",
      "  3%|▊                                | 10076/400000 [00:01<00:39, 9748.19it/s]\n",
      "  3%|▉                               | 11381/400000 [00:01<00:38, 10039.40it/s]\n",
      "  3%|█                               | 12735/400000 [00:01<00:37, 10316.44it/s]\n",
      "  4%|█                               | 14028/400000 [00:01<00:36, 10502.82it/s]\n",
      "  4%|█▏                              | 15296/400000 [00:01<00:36, 10639.61it/s]\n",
      "  4%|█▎                              | 16556/400000 [00:01<00:35, 10760.06it/s]\n",
      "  5%|█▍                              | 18106/400000 [00:01<00:34, 10979.62it/s]\n",
      "  5%|█▌                              | 19530/400000 [00:01<00:34, 11162.19it/s]\n",
      "  5%|█▋                              | 20862/400000 [00:01<00:34, 10876.60it/s]Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Miniconda3\\lib\\threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Miniconda3\\lib\\site-packages\\tqdm\\_monitor.py\", line 62, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"C:\\Miniconda3\\lib\\_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "  6%|█▊                              | 22032/400000 [00:02<00:34, 10865.71it/s]\n",
      "100%|███████████████████████████████| 400000/400000 [00:33<00:00, 12059.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/CNN4_GLOVE.ckpt\n",
      "initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [52:22<00:00, 31.42s/it]\n"
     ]
    }
   ],
   "source": [
    "test_labels=(test_df['label']-1).tolist()\n",
    "test_dataset=np.zeros((num_comments_test,max(comment_lengths)),dtype='int32')\n",
    "for i in tqdm(range(num_comments_test)):\n",
    "    comment=comment_list_test[i]\n",
    "    comment_as_word=comment.split()\n",
    "    for j,word in enumerate(comment_as_word):\n",
    "        word_index=word_dict.get(word,0)\n",
    "        test_dataset[i,j]=word_index\n",
    "with sess.as_default():\n",
    "    init.run()\n",
    "    try:\n",
    "        saver.restore(sess,model_name)\n",
    "    except:\n",
    "        print('Unexpected Error: model cannot be restored')\n",
    "    print('initialized')\n",
    "    y_pred=np.zeros((num_comments_test,1))\n",
    "    for i in tqdm(range(int(num_comments_test/test_batch_size))):\n",
    "        test_batch=test_dataset[i*test_batch_size:(i+1)*test_batch_size,:]\n",
    "        y_pred_batch=test_predictions.eval(feed_dict={test_inputs:test_batch,embedding_matrix:embeddings})\n",
    "        y_pred[i*test_batch_size:(i+1)*test_batch_size,:]=y_pred_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 86.07%, Precision: 80.79%, Recall: 87.07%, F1_score: 86.21%\n"
     ]
    }
   ],
   "source": [
    "y_true=test_labels\n",
    "accuracy=accuracy_score(y_true,y_pred)\n",
    "precision=average_precision_score(y_true,y_pred)\n",
    "recall=recall_score(y_true,y_pred)\n",
    "f1=f1_score(y_true,y_pred)\n",
    "print('Accuracy: {:4.2f}%, Precision: {:4.2f}%, Recall: {:4.2f}%, F1_score: {:4.2f}%'.format(accuracy*100,precision*100,recall*100,f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__variable_store',),\n",
       " ('__varscope',),\n",
       " 'trainable_variables',\n",
       " 'train_op',\n",
       " 'update_ops',\n",
       " 'variables']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
