{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df=pd.read_pickle('./data/train_df.pickle')\n",
    "#test_df=pd.read_pickle('./data/test_df.pickle')\n",
    "train_df=pd.read_pickle('./data/train_df_nopunc.pickle')\n",
    "test_df=pd.read_pickle('./data/test_df_nopunc.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████| 3600000/3600000 [00:30<00:00, 119400.12it/s]\n"
     ]
    }
   ],
   "source": [
    "comment_lengths=list()\n",
    "comment_list=train_df['text'].tolist()\n",
    "for i in tqdm(range(len(comment_list))):\n",
    "    comment=comment_list[i]\n",
    "    temp1=len(comment.split())\n",
    "    comment_lengths.append(temp1)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 400000/400000 [00:03<00:00, 102374.49it/s]\n"
     ]
    }
   ],
   "source": [
    "comment_lengths_test=list()\n",
    "comment_list_test=test_df['text'].tolist()\n",
    "for i in tqdm(range(len(comment_list_test))):\n",
    "    comment=comment_list_test[i]\n",
    "    temp1=len(comment.split())\n",
    "    comment_lengths_test.append(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec_simple_from_tf=np.load('./data/word2vec_simple.npz')\n",
    "word2vec_simple_from_tf=np.load('./data/word2vec_1M_FT.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=word2vec_simple_from_tf['arr_0']\n",
    "word_dict=word2vec_simple_from_tf['arr_1'].tolist()\n",
    "reverse_dict=word2vec_simple_from_tf['arr_2'].tolist()\n",
    "embedding_size=embeddings.shape[1]\n",
    "comment_vector_size=embedding_size*max(comment_lengths)\n",
    "num_comments=len(comment_list)\n",
    "train_labels=(train_df['label']).tolist()\n",
    "n_embeddings,d_embeddings=embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████| 3600000/3600000 [04:00<00:00, 14990.15it/s]\n"
     ]
    }
   ],
   "source": [
    "comments_with_word_indices=np.zeros(shape=(num_comments,max(comment_lengths)),dtype='int32')\n",
    "for i in tqdm(range(len(comment_list))):\n",
    "    comment=comment_list[i]\n",
    "    comment_words=comment.split()\n",
    "    for j,word in enumerate(comment_words):\n",
    "        comments_with_word_indices[i,j]=word_dict.get(word,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch_size):\n",
    "    batch_indices=random.sample(range(num_comments),batch_size)\n",
    "    batch_inputs=comments_with_word_indices[batch_indices,:]\n",
    "    batch_labels=np.reshape(np.asarray([train_labels[idx] for idx in batch_indices])-1,(batch_size,1))\n",
    "    return batch_inputs, batch_labels, batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "38\n",
      "[1]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#sanity check\n",
    "a=generate_batch(2) \n",
    "b=a[0][0]\n",
    "index1=a[2][0]\n",
    "c=[o for o in b if o!=0]\n",
    "print(len(c))\n",
    "print(len(comment_list[index1].split()))\n",
    "label1=a[1][0]\n",
    "print(label1)\n",
    "print(train_df['label'][index1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 400000/400000 [00:27<00:00, 14687.76it/s]\n"
     ]
    }
   ],
   "source": [
    "#creating test dataset\n",
    "num_comments_test=len(comment_list_test)\n",
    "test_labels=(test_df['label']-1).tolist()\n",
    "test_dataset=np.zeros((num_comments_test,max(comment_lengths)),dtype='int32')\n",
    "for i in tqdm(range(num_comments_test)):\n",
    "    comment=comment_list_test[i]\n",
    "    comment_as_word=comment.split()\n",
    "    for j,word in enumerate(comment_as_word):\n",
    "        word_index=word_dict.get(word,0)\n",
    "        test_dataset[i,j]=word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/CNN1_word2vec_1M_FT.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/CNN1_word2vec_1M_FT.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n",
      "Step: 150 ,Average loss in 150 steps: 0.224 ,batch time: 26.04 ,Run time: 191.54 Batch Accuracy: 89.06 Valid accuracy: 91.80\n",
      "Step: 300 ,Average loss in 150 steps: 0.235 ,batch time: 23.94 ,Run time: 186.66 Batch Accuracy: 92.19 Valid accuracy: 91.20\n",
      "Step: 450 ,Average loss in 150 steps: 0.220 ,batch time: 23.99 ,Run time: 186.58 Batch Accuracy: 89.06 Valid accuracy: 91.80\n",
      "Step: 600 ,Average loss in 150 steps: 0.229 ,batch time: 21.80 ,Run time: 185.86 Batch Accuracy: 95.31 Valid accuracy: 92.40\n",
      "Step: 750 ,Average loss in 150 steps: 0.224 ,batch time: 21.12 ,Run time: 189.95 Batch Accuracy: 89.06 Valid accuracy: 91.00\n",
      "Step: 900 ,Average loss in 150 steps: 0.226 ,batch time: 20.34 ,Run time: 190.90 Batch Accuracy: 90.62 Valid accuracy: 92.40\n",
      "Step: 1050 ,Average loss in 150 steps: 0.226 ,batch time: 19.98 ,Run time: 198.59 Batch Accuracy: 96.88 Valid accuracy: 93.60\n",
      "Step: 1200 ,Average loss in 150 steps: 0.224 ,batch time: 18.44 ,Run time: 195.56 Batch Accuracy: 89.06 Valid accuracy: 94.80\n",
      "Step: 1350 ,Average loss in 150 steps: 0.228 ,batch time: 18.54 ,Run time: 186.04 Batch Accuracy: 87.50 Valid accuracy: 91.20\n",
      "Step: 1500 ,Average loss in 150 steps: 0.239 ,batch time: 17.20 ,Run time: 185.58 Batch Accuracy: 90.62 Valid accuracy: 90.80\n",
      "Step: 1650 ,Average loss in 150 steps: 0.227 ,batch time: 17.46 ,Run time: 186.00 Batch Accuracy: 82.81 Valid accuracy: 92.20\n",
      "Step: 1800 ,Average loss in 150 steps: 0.216 ,batch time: 16.76 ,Run time: 186.24 Batch Accuracy: 90.62 Valid accuracy: 91.60\n",
      "Step: 1950 ,Average loss in 150 steps: 0.211 ,batch time: 16.13 ,Run time: 190.87 Batch Accuracy: 95.31 Valid accuracy: 93.00\n",
      "Step: 2100 ,Average loss in 150 steps: 0.226 ,batch time: 15.65 ,Run time: 191.34 Batch Accuracy: 90.62 Valid accuracy: 90.20\n",
      "Step: 2250 ,Average loss in 150 steps: 0.226 ,batch time: 15.55 ,Run time: 188.89 Batch Accuracy: 92.19 Valid accuracy: 91.40\n",
      "Step: 2400 ,Average loss in 150 steps: 0.229 ,batch time: 14.71 ,Run time: 186.60 Batch Accuracy: 95.31 Valid accuracy: 91.00\n",
      "Step: 2550 ,Average loss in 150 steps: 0.230 ,batch time: 14.00 ,Run time: 188.66 Batch Accuracy: 92.19 Valid accuracy: 92.80\n",
      "Step: 2700 ,Average loss in 150 steps: 0.218 ,batch time: 14.71 ,Run time: 188.86 Batch Accuracy: 89.06 Valid accuracy: 91.40\n",
      "Step: 2850 ,Average loss in 150 steps: 0.225 ,batch time: 13.95 ,Run time: 208.44 Batch Accuracy: 90.62 Valid accuracy: 91.40\n",
      "Step: 3000 ,Average loss in 150 steps: 0.226 ,batch time: 13.49 ,Run time: 195.58 Batch Accuracy: 93.75 Valid accuracy: 91.60\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "num_steps=3001\n",
    "batch_size=64\n",
    "graph=tf.Graph()\n",
    "batch_timing=0\n",
    "run_timing=0\n",
    "num_filters=100\n",
    "kernel_size=2\n",
    "restore_sess=1\n",
    "test_batch_size=int(num_comments_test/100)\n",
    "validation_batch_size=500\n",
    "\n",
    "#model_name=\"./ckpt/LR_word2vec.ckpt\"\n",
    "model_name=\"./ckpt/CNN1_word2vec_1M_FT.ckpt\"\n",
    "steps_display=min(int((num_steps-1)/20),1000)\n",
    "with graph.as_default():\n",
    "    inputs=tf.placeholder(tf.int32, shape=(batch_size,max(comment_lengths)))\n",
    "    test_inputs=tf.placeholder(tf.int32, shape=(test_batch_size,max(comment_lengths)))\n",
    "    validation_inputs=tf.placeholder(tf.int32, shape=(validation_batch_size,max(comment_lengths)))\n",
    "    labels=tf.placeholder(tf.float32, shape=(batch_size,1))\n",
    "    embedding_matrix=tf.placeholder(tf.float32, shape=(n_embeddings,d_embeddings))\n",
    "    layer1_weights=tf.Variable(tf.truncated_normal([kernel_size,d_embeddings,num_filters],stddev=0.1))\n",
    "    layer1_biases = tf.Variable(tf.ones([num_filters]))\n",
    "    hidden_weights=tf.Variable(tf.truncated_normal([max(comment_lengths)*num_filters,1],stddev=0.1))\n",
    "    hidden_biases=tf.Variable(tf.constant(1.0, shape=[1]))\n",
    "    \n",
    "    def model_graph(data):\n",
    "        batch_embeddings=tf.nn.embedding_lookup(embedding_matrix,data)\n",
    "        conv1=tf.nn.conv1d(batch_embeddings,layer1_weights,stride=1,padding='SAME')\n",
    "        conv1=tf.nn.relu(conv1)\n",
    "        shape=conv1.get_shape().as_list()\n",
    "        conv1=tf.reshape(conv1,[shape[0],shape[1],shape[2],1])\n",
    "        pool1=tf.nn.max_pool(conv1,[1,1,num_filters,1],strides=[1,1,1,1],padding='SAME')\n",
    "        shape=pool1.get_shape().as_list()\n",
    "        flat1=tf.reshape(pool1,[shape[0],shape[1]*shape[2]*shape[3]])\n",
    "        flat1=tf.nn.dropout(flat1,keep_prob=0.5)\n",
    "        y_pred_model=tf.matmul(flat1,hidden_weights)+hidden_biases\n",
    "        return y_pred_model\n",
    "    \n",
    "    y_pred=model_graph(inputs)\n",
    "    y_pred_test=model_graph(test_inputs)\n",
    "    y_pred_validation=model_graph(validation_inputs)\n",
    "    test_predictions=tf.round(tf.sigmoid(y_pred_test))\n",
    "    validation_predictions=tf.round(tf.sigmoid(y_pred_validation))\n",
    "    train_predictions=tf.round(tf.sigmoid(y_pred))\n",
    "    x_entropy=tf.nn.sigmoid_cross_entropy_with_logits(logits=y_pred,labels=labels)\n",
    "    loss =tf.reduce_mean(x_entropy)\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver=tf.train.Saver()\n",
    "\n",
    "sess=tf.Session(graph=graph)\n",
    "with sess.as_default():\n",
    "    init.run()\n",
    "    if restore_sess==1:\n",
    "        try:\n",
    "            saver.restore(sess,model_name)\n",
    "        except:\n",
    "            print('Unexpected Error: model cannot be restored')\n",
    "    print('initialized')\n",
    "    loss_val_sum=0\n",
    "    for i in range(num_steps):\n",
    "        time1=time.time()\n",
    "        batch_inputs,batch_labels,_=generate_batch(batch_size)\n",
    "        time2=time.time()\n",
    "        feed_dict={inputs:batch_inputs,labels:batch_labels,embedding_matrix:embeddings}\n",
    "        _,loss_val,train_preds=sess.run([optimizer,loss,train_predictions],feed_dict=feed_dict)\n",
    "        time3=time.time()\n",
    "        batch_timing += time2-time1\n",
    "        run_timing += time3-time2\n",
    "        loss_val_sum += loss_val\n",
    "        if i % steps_display==0 and i!=0:\n",
    "            validation_batch,validation_labels,_=generate_batch(validation_batch_size)\n",
    "            #validation_batch=batch_inputs\n",
    "            #validation_labels=batch_labels\n",
    "            validation_preds=sess.run(validation_predictions,\n",
    "                                      feed_dict={validation_inputs:validation_batch,embedding_matrix:embeddings})            \n",
    "            print('Step:',i,\n",
    "                  ',Average loss in',steps_display, 'steps:',\"{0:.3f}\".format(loss_val_sum/steps_display),',batch time:'\n",
    "                  ,\"{0:.2f}\".format(batch_timing),',Run time:',\"{0:.2f}\".format(run_timing)\n",
    "                  ,'Batch Accuracy:', \"{:4.2f}\".format(100*accuracy_score(batch_labels,train_preds))\n",
    "                  ,'Valid accuracy:',\"{:4.2f}\".format(100*accuracy_score(validation_labels,validation_preds)))\n",
    "            batch_timing=0\n",
    "            run_timing=0\n",
    "            loss_val_sum=0\n",
    "    try:\n",
    "        saver.save(sess,model_name)\n",
    "        print('Model saved!')\n",
    "    except:\n",
    "        print('Model could not be saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/CNN1_word2vec_1M_FT.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./ckpt/CNN1_word2vec_1M_FT.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 100/100 [53:11<00:00, 31.91s/it]\n"
     ]
    }
   ],
   "source": [
    "with sess.as_default():\n",
    "    init.run()\n",
    "    try:\n",
    "        saver.restore(sess,model_name)\n",
    "    except:\n",
    "        print('Unexpected Error: model cannot be restored')\n",
    "    print('initialized')\n",
    "    y_pred=np.zeros((num_comments_test,1))\n",
    "    for i in tqdm(range(int(num_comments_test/test_batch_size))):\n",
    "        test_batch=test_dataset[i*test_batch_size:(i+1)*test_batch_size,:]\n",
    "        y_pred_batch=test_predictions.eval(feed_dict={test_inputs:test_batch,embedding_matrix:embeddings})\n",
    "        y_pred[i*test_batch_size:(i+1)*test_batch_size,:]=y_pred_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.69%, Precision: 85.67%, Recall: 94.71%, F1_score: 91.05%\n"
     ]
    }
   ],
   "source": [
    "y_true=test_labels\n",
    "accuracy=accuracy_score(y_true,y_pred)\n",
    "precision=average_precision_score(y_true,y_pred)\n",
    "recall=recall_score(y_true,y_pred)\n",
    "f1=f1_score(y_true,y_pred)\n",
    "print('Accuracy: {:4.2f}%, Precision: {:4.2f}%, Recall: {:4.2f}%, F1_score: {:4.2f}%'.format(accuracy*100,precision*100,recall*100,f1*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('__variable_store',),\n",
       " ('__varscope',),\n",
       " 'trainable_variables',\n",
       " 'train_op',\n",
       " 'update_ops',\n",
       " 'variables']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validation_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
