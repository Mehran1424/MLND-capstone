{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_pickle('./data/train_df_nopunc.pickle')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=train_df['text'].tolist()\n",
    "txt=' '.join(a)\n",
    "del a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt=txt.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_words=1000000\n",
    "words=txt.split()\n",
    "count=collections.Counter(words).most_common(n_words - 1)\n",
    "count.insert(0,('rare_word',-1))\n",
    "i=0\n",
    "word_dict=dict()\n",
    "for word,num in count:\n",
    "    word_dict[word]=i\n",
    "    i+=1\n",
    "\n",
    "words_num_list=list()\n",
    "rare_word_count=0\n",
    "for word in words:\n",
    "    ind=word_dict.get(word,0)\n",
    "    words_num_list.append(ind)\n",
    "    if ind==0:\n",
    "        rare_word_count+=1\n",
    "count[0]=('rare_word',rare_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "global_counter=0\n",
    "def generate_batch_seq(batch_size,skip_window,num_skip):\n",
    "    global global_counter\n",
    "    batch = np.ndarray(shape=(batch_size), dtype=np.int32)\n",
    "    training_labels = np.ndarray(shape=(batch_size,1), dtype=np.int32)    \n",
    "    window_span=skip_window * 2 + 1\n",
    "    for i in range(batch_size//num_skip):\n",
    "        if global_counter+window_span>len(words_num_list):\n",
    "            global_counter=0\n",
    "        word_window=words_num_list[global_counter:global_counter+window_span]\n",
    "        context_indices_in_window=[w for w in range(window_span) if w!=skip_window]\n",
    "        selected_indices=random.sample(context_indices_in_window,num_skip)\n",
    "        for j,selected_index in enumerate(selected_indices):\n",
    "            context_word=word_window[selected_index]\n",
    "            center_word=word_window[skip_window]\n",
    "            batch[i*num_skip+j]=context_word\n",
    "            training_labels[i*num_skip+j]=center_word\n",
    "        global_counter +=1\n",
    "    return batch,training_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0 loss= 362.456\n",
      "1000 loss= 255.112\n",
      "2000 loss= 210.831\n",
      "3000 loss= 209.682\n",
      "4000 loss= 191.136\n",
      "5000 loss= 153.3\n",
      "6000 loss= 204.06\n",
      "7000 loss= 134.71\n",
      "8000 loss= 178.065\n",
      "9000 loss= 158.172\n",
      "10000 loss= 201.492\n",
      "11000 loss= 152.143\n",
      "12000 loss= 105.094\n",
      "13000 loss= 88.0355\n",
      "14000 loss= 123.605\n",
      "15000 loss= 139.512\n",
      "16000 loss= 69.6525\n",
      "17000 loss= 130.037\n",
      "18000 loss= 137.007\n",
      "19000 loss= 92.6008\n",
      "20000 loss= 80.3961\n",
      "21000 loss= 118.776\n",
      "22000 loss= 129.41\n",
      "23000 loss= 174.568\n",
      "24000 loss= 125.567\n",
      "25000 loss= 103.651\n",
      "26000 loss= 91.5719\n",
      "27000 loss= 55.8084\n",
      "28000 loss= 103.119\n",
      "29000 loss= 94.2873\n",
      "30000 loss= 132.64\n",
      "31000 loss= 91.2267\n",
      "32000 loss= 141.809\n",
      "33000 loss= 94.4632\n",
      "34000 loss= 98.974\n",
      "35000 loss= 57.2071\n",
      "36000 loss= 96.4389\n",
      "37000 loss= 47.6846\n",
      "38000 loss= 69.5843\n",
      "39000 loss= 149.928\n",
      "40000 loss= 120.113\n",
      "41000 loss= 51.5818\n",
      "42000 loss= 92.4053\n",
      "43000 loss= 44.8467\n",
      "44000 loss= 39.4408\n",
      "45000 loss= 78.0928\n",
      "46000 loss= 40.635\n",
      "47000 loss= 92.8686\n",
      "48000 loss= 70.8508\n",
      "49000 loss= 26.8771\n",
      "50000 loss= 60.1272\n",
      "51000 loss= 106.081\n",
      "52000 loss= 51.5987\n",
      "53000 loss= 99.71\n",
      "54000 loss= 86.7924\n",
      "55000 loss= 66.265\n",
      "56000 loss= 116.833\n",
      "57000 loss= 69.5464\n",
      "58000 loss= 39.1138\n",
      "59000 loss= 67.8004\n",
      "60000 loss= 64.9827\n",
      "61000 loss= 86.4815\n",
      "62000 loss= 105.797\n",
      "63000 loss= 50.5511\n",
      "64000 loss= 101.645\n",
      "65000 loss= 28.5208\n",
      "66000 loss= 49.1339\n",
      "67000 loss= 85.6526\n",
      "68000 loss= 28.1752\n",
      "69000 loss= 47.6963\n",
      "70000 loss= 52.7274\n",
      "71000 loss= 16.5315\n",
      "72000 loss= 42.0256\n",
      "73000 loss= 31.4036\n",
      "74000 loss= 18.9836\n",
      "75000 loss= 75.9747\n",
      "76000 loss= 56.533\n",
      "77000 loss= 27.782\n",
      "78000 loss= 39.1735\n",
      "79000 loss= 51.277\n",
      "80000 loss= 63.3406\n",
      "81000 loss= 82.8221\n",
      "82000 loss= 38.5438\n",
      "83000 loss= 85.1265\n",
      "84000 loss= 63.8072\n",
      "85000 loss= 28.3998\n",
      "86000 loss= 39.6791\n",
      "87000 loss= 48.9876\n",
      "88000 loss= 16.5875\n",
      "89000 loss= 29.2928\n",
      "90000 loss= 51.7434\n",
      "91000 loss= 52.8736\n",
      "92000 loss= 64.0783\n",
      "93000 loss= 64.0947\n",
      "94000 loss= 28.6697\n",
      "95000 loss= 61.5381\n",
      "96000 loss= 27.9505\n",
      "97000 loss= 46.6038\n",
      "98000 loss= 28.808\n",
      "99000 loss= 39.4948\n",
      "100000 loss= 20.2262\n",
      "101000 loss= 65.4126\n",
      "102000 loss= 38.963\n",
      "103000 loss= 37.0544\n",
      "104000 loss= 20.0695\n",
      "105000 loss= 93.7757\n",
      "106000 loss= 40.1796\n",
      "107000 loss= 28.8333\n",
      "108000 loss= 30.3813\n",
      "109000 loss= 22.8888\n",
      "110000 loss= 76.1571\n",
      "111000 loss= 28.947\n",
      "112000 loss= 33.3524\n",
      "113000 loss= 42.1762\n",
      "114000 loss= 37.9541\n",
      "115000 loss= 28.4471\n",
      "116000 loss= 26.2116\n",
      "117000 loss= 53.8986\n",
      "118000 loss= 16.001\n",
      "119000 loss= 16.863\n",
      "120000 loss= 38.5828\n",
      "121000 loss= 20.3778\n",
      "122000 loss= 26.5558\n",
      "123000 loss= 19.3883\n",
      "124000 loss= 27.8925\n",
      "125000 loss= 16.2685\n",
      "126000 loss= 43.9336\n",
      "127000 loss= 6.72886\n",
      "128000 loss= 46.1389\n",
      "129000 loss= 17.6007\n",
      "130000 loss= 45.5901\n",
      "131000 loss= 17.0783\n",
      "132000 loss= 6.93488\n",
      "133000 loss= 42.1925\n",
      "134000 loss= 16.3768\n",
      "135000 loss= 7.82611\n",
      "136000 loss= 33.6777\n",
      "137000 loss= 28.5021\n",
      "138000 loss= 5.39488\n",
      "139000 loss= 28.594\n",
      "140000 loss= 42.3556\n",
      "141000 loss= 42.9177\n",
      "142000 loss= 32.867\n",
      "143000 loss= 18.7591\n",
      "144000 loss= 20.997\n",
      "145000 loss= 32.0867\n",
      "146000 loss= 4.63862\n",
      "147000 loss= 15.5119\n",
      "148000 loss= 64.0308\n",
      "149000 loss= 16.6474\n",
      "150000 loss= 15.9471\n",
      "151000 loss= 17.5212\n",
      "152000 loss= 6.85637\n",
      "153000 loss= 28.2988\n",
      "154000 loss= 18.3959\n",
      "155000 loss= 16.536\n",
      "156000 loss= 17.2302\n",
      "157000 loss= 10.9793\n",
      "158000 loss= 4.82792\n",
      "159000 loss= 28.2412\n",
      "160000 loss= 28.3052\n",
      "161000 loss= 39.7273\n",
      "162000 loss= 22.8531\n",
      "163000 loss= 40.6979\n",
      "164000 loss= 4.4928\n",
      "165000 loss= 40.041\n",
      "166000 loss= 53.6199\n",
      "167000 loss= 15.4463\n",
      "168000 loss= 16.3966\n",
      "169000 loss= 15.8498\n",
      "170000 loss= 38.2962\n",
      "171000 loss= 52.0724\n",
      "172000 loss= 32.5257\n",
      "173000 loss= 17.0372\n",
      "174000 loss= 26.7905\n",
      "175000 loss= 39.8477\n",
      "176000 loss= 15.9566\n",
      "177000 loss= 17.3432\n",
      "178000 loss= 40.7682\n",
      "179000 loss= 28.3764\n",
      "180000 loss= 17.249\n",
      "181000 loss= 16.478\n",
      "182000 loss= 39.0382\n",
      "183000 loss= 15.8218\n",
      "184000 loss= 40.0263\n",
      "185000 loss= 3.78794\n",
      "186000 loss= 4.60426\n",
      "187000 loss= 18.659\n",
      "188000 loss= 41.7894\n",
      "189000 loss= 28.2734\n",
      "190000 loss= 39.4445\n",
      "191000 loss= 27.9453\n",
      "192000 loss= 19.261\n",
      "193000 loss= 5.27113\n",
      "194000 loss= 16.7163\n",
      "195000 loss= 16.5322\n",
      "196000 loss= 11.072\n",
      "197000 loss= 27.2416\n",
      "198000 loss= 39.1144\n",
      "199000 loss= 4.11696\n",
      "200000 loss= 28.1495\n",
      "201000 loss= 4.99456\n",
      "202000 loss= 29.5132\n",
      "203000 loss= 5.89578\n",
      "204000 loss= 43.7407\n",
      "205000 loss= 28.8024\n",
      "206000 loss= 5.97242\n",
      "207000 loss= 50.629\n",
      "208000 loss= 17.74\n",
      "209000 loss= 41.1341\n",
      "210000 loss= 6.31843\n",
      "211000 loss= 40.1646\n",
      "212000 loss= 16.2087\n",
      "213000 loss= 16.9969\n",
      "214000 loss= 5.20697\n",
      "215000 loss= 16.024\n",
      "216000 loss= 28.2907\n",
      "217000 loss= 31.2476\n",
      "218000 loss= 4.89001\n",
      "219000 loss= 15.434\n",
      "220000 loss= 28.1037\n",
      "221000 loss= 5.18059\n",
      "222000 loss= 16.0336\n",
      "223000 loss= 28.4798\n",
      "224000 loss= 16.1877\n",
      "225000 loss= 16.9156\n",
      "226000 loss= 16.9387\n",
      "227000 loss= 16.7481\n",
      "228000 loss= 6.21678\n",
      "229000 loss= 35.0091\n",
      "230000 loss= 4.44345\n",
      "231000 loss= 4.8991\n",
      "232000 loss= 27.6658\n",
      "233000 loss= 42.9533\n",
      "234000 loss= 14.9911\n",
      "235000 loss= 4.65037\n",
      "236000 loss= 12.4614\n",
      "237000 loss= 27.9242\n",
      "238000 loss= 6.49242\n",
      "239000 loss= 31.0575\n",
      "240000 loss= 4.89779\n",
      "241000 loss= 19.6461\n",
      "242000 loss= 8.92496\n",
      "243000 loss= 22.2478\n",
      "244000 loss= 21.3209\n",
      "245000 loss= 21.2643\n",
      "246000 loss= 11.4739\n",
      "247000 loss= 6.21634\n",
      "248000 loss= 16.2294\n",
      "249000 loss= 4.72789\n",
      "250000 loss= 16.7506\n",
      "251000 loss= 4.97638\n",
      "252000 loss= 40.9923\n",
      "253000 loss= 13.6555\n",
      "254000 loss= 16.0191\n",
      "255000 loss= 4.22019\n",
      "256000 loss= 12.1134\n",
      "257000 loss= 40.6543\n",
      "258000 loss= 4.50114\n",
      "259000 loss= 4.58309\n",
      "260000 loss= 4.72306\n",
      "261000 loss= 6.40219\n",
      "262000 loss= 4.5678\n",
      "263000 loss= 4.68728\n",
      "264000 loss= 17.9683\n",
      "265000 loss= 5.25641\n",
      "266000 loss= 15.5316\n",
      "267000 loss= 27.9838\n",
      "268000 loss= 6.10559\n",
      "269000 loss= 4.58096\n",
      "270000 loss= 4.49343\n",
      "271000 loss= 15.9733\n",
      "272000 loss= 4.43541\n",
      "273000 loss= 23.3756\n",
      "274000 loss= 4.85443\n",
      "275000 loss= 4.87369\n",
      "276000 loss= 5.16407\n",
      "277000 loss= 16.8042\n",
      "278000 loss= 17.1348\n",
      "279000 loss= 16.869\n",
      "280000 loss= 4.80024\n",
      "281000 loss= 6.34976\n",
      "282000 loss= 39.0057\n",
      "283000 loss= 17.869\n",
      "284000 loss= 5.5826\n",
      "285000 loss= 4.74815\n",
      "286000 loss= 5.30235\n",
      "287000 loss= 4.43284\n",
      "288000 loss= 9.10228\n",
      "289000 loss= 4.60006\n",
      "290000 loss= 4.6157\n",
      "291000 loss= 4.80964\n",
      "292000 loss= 16.8737\n",
      "293000 loss= 14.9024\n",
      "294000 loss= 16.4272\n",
      "295000 loss= 4.85863\n",
      "296000 loss= 4.07392\n",
      "297000 loss= 19.6383\n",
      "298000 loss= 16.6877\n",
      "299000 loss= 15.9614\n",
      "300000 loss= 4.14702\n",
      "301000 loss= 16.4534\n",
      "302000 loss= 16.7753\n",
      "303000 loss= 4.92016\n",
      "304000 loss= 4.60648\n",
      "305000 loss= 4.70787\n",
      "306000 loss= 43.9274\n",
      "307000 loss= 16.1296\n",
      "308000 loss= 4.42823\n",
      "309000 loss= 9.27729\n",
      "310000 loss= 30.283\n",
      "311000 loss= 4.74775\n",
      "312000 loss= 4.1891\n",
      "313000 loss= 5.29467\n",
      "314000 loss= 4.75025\n",
      "315000 loss= 4.70061\n",
      "316000 loss= 9.9927\n",
      "317000 loss= 4.41783\n",
      "318000 loss= 4.10302\n",
      "319000 loss= 4.641\n",
      "320000 loss= 5.52636\n",
      "321000 loss= 28.0908\n",
      "322000 loss= 4.37539\n",
      "323000 loss= 5.6251\n",
      "324000 loss= 4.51988\n",
      "325000 loss= 4.80955\n",
      "326000 loss= 4.36673\n",
      "327000 loss= 16.4949\n",
      "328000 loss= 28.95\n",
      "329000 loss= 4.76519\n",
      "330000 loss= 4.85115\n",
      "331000 loss= 4.79436\n",
      "332000 loss= 5.62775\n",
      "333000 loss= 4.7199\n",
      "334000 loss= 17.0153\n",
      "335000 loss= 4.81458\n",
      "336000 loss= 15.8343\n",
      "337000 loss= 39.4033\n",
      "338000 loss= 5.14929\n",
      "339000 loss= 4.65253\n",
      "340000 loss= 4.57028\n",
      "341000 loss= 5.26912\n",
      "342000 loss= 4.23\n",
      "343000 loss= 5.25674\n",
      "344000 loss= 4.3509\n",
      "345000 loss= 5.23087\n",
      "346000 loss= 4.31938\n",
      "347000 loss= 16.8854\n",
      "348000 loss= 4.57162\n",
      "349000 loss= 6.02483\n",
      "350000 loss= 8.50739\n",
      "351000 loss= 16.136\n",
      "352000 loss= 4.77211\n",
      "353000 loss= 4.72625\n",
      "354000 loss= 6.74833\n",
      "355000 loss= 4.86147\n",
      "356000 loss= 22.5955\n",
      "357000 loss= 7.75858\n",
      "358000 loss= 16.8656\n",
      "359000 loss= 7.4912\n",
      "360000 loss= 5.02072\n",
      "361000 loss= 6.48052\n",
      "362000 loss= 4.80416\n",
      "363000 loss= 4.97648\n",
      "364000 loss= 4.50179\n",
      "365000 loss= 16.9325\n",
      "366000 loss= 16.2127\n",
      "367000 loss= 17.0077\n",
      "368000 loss= 4.39672\n",
      "369000 loss= 18.5496\n",
      "370000 loss= 5.76601\n",
      "371000 loss= 25.203\n",
      "372000 loss= 4.79069\n",
      "373000 loss= 4.78588\n",
      "374000 loss= 11.6395\n",
      "375000 loss= 16.5698\n",
      "376000 loss= 10.1169\n",
      "377000 loss= 4.45885\n",
      "378000 loss= 5.09306\n",
      "379000 loss= 4.60636\n",
      "380000 loss= 4.60724\n",
      "381000 loss= 27.8805\n",
      "382000 loss= 8.96131\n",
      "383000 loss= 5.18174\n",
      "384000 loss= 4.58895\n",
      "385000 loss= 5.48168\n",
      "386000 loss= 5.59311\n",
      "387000 loss= 20.5135\n",
      "388000 loss= 16.4874\n",
      "389000 loss= 10.1132\n",
      "390000 loss= 13.7138\n",
      "391000 loss= 16.2552\n",
      "392000 loss= 4.61583\n",
      "393000 loss= 4.1719\n",
      "394000 loss= 4.85292\n",
      "395000 loss= 6.04634\n",
      "396000 loss= 4.92962\n",
      "397000 loss= 18.203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398000 loss= 4.75186\n",
      "399000 loss= 8.13961\n",
      "400000 loss= 12.861\n",
      "401000 loss= 4.59393\n",
      "402000 loss= 4.6815\n",
      "403000 loss= 16.1662\n",
      "404000 loss= 4.47623\n",
      "405000 loss= 31.8226\n",
      "406000 loss= 17.2117\n",
      "407000 loss= 4.66666\n",
      "408000 loss= 5.86273\n",
      "409000 loss= 4.27969\n",
      "410000 loss= 6.2808\n",
      "411000 loss= 4.28573\n",
      "412000 loss= 6.8181\n",
      "413000 loss= 7.02869\n",
      "414000 loss= 4.66766\n",
      "415000 loss= 4.87405\n",
      "416000 loss= 5.16655\n",
      "417000 loss= 20.5234\n",
      "418000 loss= 10.3612\n",
      "419000 loss= 9.38875\n",
      "420000 loss= 29.5113\n",
      "421000 loss= 4.0614\n",
      "422000 loss= 4.78751\n",
      "423000 loss= 20.2849\n",
      "424000 loss= 4.61323\n",
      "425000 loss= 3.53558\n",
      "426000 loss= 11.2309\n",
      "427000 loss= 5.18555\n",
      "428000 loss= 4.75514\n",
      "429000 loss= 4.75249\n",
      "430000 loss= 5.00557\n",
      "431000 loss= 28.9355\n",
      "432000 loss= 29.9887\n",
      "433000 loss= 4.67735\n",
      "434000 loss= 4.65641\n",
      "435000 loss= 4.57053\n",
      "436000 loss= 11.0733\n",
      "437000 loss= 4.17341\n",
      "438000 loss= 5.33555\n",
      "439000 loss= 4.85981\n",
      "440000 loss= 5.17513\n",
      "441000 loss= 6.54409\n",
      "442000 loss= 5.2277\n",
      "443000 loss= 3.98153\n",
      "444000 loss= 12.3572\n",
      "445000 loss= 4.14431\n",
      "446000 loss= 6.08398\n",
      "447000 loss= 8.4962\n",
      "448000 loss= 27.3419\n",
      "449000 loss= 4.48683\n",
      "450000 loss= 4.82641\n",
      "451000 loss= 4.54434\n",
      "452000 loss= 6.79733\n",
      "453000 loss= 9.13431\n",
      "454000 loss= 4.69779\n",
      "455000 loss= 7.28532\n",
      "456000 loss= 4.44245\n",
      "457000 loss= 5.01025\n",
      "458000 loss= 4.68542\n",
      "459000 loss= 21.027\n",
      "460000 loss= 4.36327\n",
      "461000 loss= 4.8131\n",
      "462000 loss= 4.66875\n",
      "463000 loss= 4.31465\n",
      "464000 loss= 4.49183\n",
      "465000 loss= 4.56504\n",
      "466000 loss= 4.19332\n",
      "467000 loss= 11.2248\n",
      "468000 loss= 4.91298\n",
      "469000 loss= 13.052\n",
      "470000 loss= 4.1009\n",
      "471000 loss= 16.16\n",
      "472000 loss= 4.92408\n",
      "473000 loss= 4.04929\n",
      "474000 loss= 3.88264\n",
      "475000 loss= 5.11245\n",
      "476000 loss= 4.49774\n",
      "477000 loss= 4.71699\n",
      "478000 loss= 4.61522\n",
      "479000 loss= 7.49171\n",
      "480000 loss= 4.67761\n",
      "481000 loss= 16.7611\n",
      "482000 loss= 30.1591\n",
      "483000 loss= 4.17318\n",
      "484000 loss= 4.38343\n",
      "485000 loss= 6.21639\n",
      "486000 loss= 4.61637\n",
      "487000 loss= 4.59487\n",
      "488000 loss= 5.1477\n",
      "489000 loss= 5.41625\n",
      "490000 loss= 4.08407\n",
      "491000 loss= 6.23866\n",
      "492000 loss= 4.51932\n",
      "493000 loss= 4.99242\n",
      "494000 loss= 6.44334\n",
      "495000 loss= 4.98875\n",
      "496000 loss= 4.15534\n",
      "497000 loss= 4.80403\n",
      "498000 loss= 4.52342\n",
      "499000 loss= 4.23909\n",
      "500000 loss= 4.45103\n",
      "501000 loss= 9.91216\n",
      "502000 loss= 4.88465\n",
      "503000 loss= 4.94393\n",
      "504000 loss= 12.15\n",
      "505000 loss= 4.88035\n",
      "506000 loss= 4.62241\n",
      "507000 loss= 5.06609\n",
      "508000 loss= 17.5518\n",
      "509000 loss= 16.7985\n",
      "510000 loss= 4.75045\n",
      "511000 loss= 4.67216\n",
      "512000 loss= 5.1238\n",
      "513000 loss= 8.04579\n",
      "514000 loss= 4.29356\n",
      "515000 loss= 4.73617\n",
      "516000 loss= 3.59137\n",
      "517000 loss= 5.81914\n",
      "518000 loss= 4.33657\n",
      "519000 loss= 4.34644\n",
      "520000 loss= 18.1082\n",
      "521000 loss= 17.6821\n",
      "522000 loss= 5.15546\n",
      "523000 loss= 4.6516\n",
      "524000 loss= 5.25468\n",
      "525000 loss= 4.48161\n",
      "526000 loss= 4.53741\n",
      "527000 loss= 4.40825\n",
      "528000 loss= 5.08797\n",
      "529000 loss= 4.51577\n",
      "530000 loss= 3.8685\n",
      "531000 loss= 4.39083\n",
      "532000 loss= 20.342\n",
      "533000 loss= 5.05367\n",
      "534000 loss= 4.63237\n",
      "535000 loss= 9.14456\n",
      "536000 loss= 12.1146\n",
      "537000 loss= 14.2291\n",
      "538000 loss= 4.31369\n",
      "539000 loss= 4.5256\n",
      "540000 loss= 17.8924\n",
      "541000 loss= 3.9169\n",
      "542000 loss= 4.47265\n",
      "543000 loss= 18.4763\n",
      "544000 loss= 4.40021\n",
      "545000 loss= 4.43785\n",
      "546000 loss= 5.51315\n",
      "547000 loss= 4.40928\n",
      "548000 loss= 5.03332\n",
      "549000 loss= 4.23619\n",
      "550000 loss= 4.37764\n",
      "551000 loss= 4.39693\n",
      "552000 loss= 4.62576\n",
      "553000 loss= 4.54193\n",
      "554000 loss= 5.39996\n",
      "555000 loss= 4.47251\n",
      "556000 loss= 4.45842\n",
      "557000 loss= 4.97523\n",
      "558000 loss= 4.81551\n",
      "559000 loss= 4.66344\n",
      "560000 loss= 4.53565\n",
      "561000 loss= 17.0705\n",
      "562000 loss= 4.41781\n",
      "563000 loss= 5.16449\n",
      "564000 loss= 5.08983\n",
      "565000 loss= 4.58942\n",
      "566000 loss= 11.2136\n",
      "567000 loss= 10.5633\n",
      "568000 loss= 7.07428\n",
      "569000 loss= 4.77116\n",
      "570000 loss= 6.01343\n",
      "571000 loss= 4.42615\n",
      "572000 loss= 13.4434\n",
      "573000 loss= 5.2579\n",
      "574000 loss= 4.83722\n",
      "575000 loss= 19.005\n",
      "576000 loss= 4.34685\n",
      "577000 loss= 4.62539\n",
      "578000 loss= 4.83076\n",
      "579000 loss= 4.5957\n",
      "580000 loss= 9.08528\n",
      "581000 loss= 7.70381\n",
      "582000 loss= 4.55645\n",
      "583000 loss= 4.67999\n",
      "584000 loss= 4.54011\n",
      "585000 loss= 4.40416\n",
      "586000 loss= 5.33281\n",
      "587000 loss= 4.7051\n",
      "588000 loss= 4.51208\n",
      "589000 loss= 16.4726\n",
      "590000 loss= 4.85741\n",
      "591000 loss= 4.55913\n",
      "592000 loss= 4.71108\n",
      "593000 loss= 8.98823\n",
      "594000 loss= 4.67405\n",
      "595000 loss= 4.61418\n",
      "596000 loss= 4.58936\n",
      "597000 loss= 16.9427\n",
      "598000 loss= 6.55177\n",
      "599000 loss= 16.5417\n",
      "600000 loss= 4.52125\n",
      "601000 loss= 5.01621\n",
      "602000 loss= 5.70706\n",
      "603000 loss= 5.02195\n",
      "604000 loss= 4.72369\n",
      "605000 loss= 7.01555\n",
      "606000 loss= 4.56965\n",
      "607000 loss= 9.78018\n",
      "608000 loss= 5.04943\n",
      "609000 loss= 4.82432\n",
      "610000 loss= 4.48975\n",
      "611000 loss= 4.52622\n",
      "612000 loss= 4.69552\n",
      "613000 loss= 4.44712\n",
      "614000 loss= 4.06779\n",
      "615000 loss= 6.66213\n",
      "616000 loss= 4.57185\n",
      "617000 loss= 4.55353\n",
      "618000 loss= 4.8\n",
      "619000 loss= 4.24079\n",
      "620000 loss= 5.40422\n",
      "621000 loss= 3.96954\n",
      "622000 loss= 5.30209\n",
      "623000 loss= 4.21844\n",
      "624000 loss= 5.2495\n",
      "625000 loss= 21.7521\n",
      "626000 loss= 4.9309\n",
      "627000 loss= 7.57718\n",
      "628000 loss= 4.23215\n",
      "629000 loss= 4.74405\n",
      "630000 loss= 4.93734\n",
      "631000 loss= 4.95421\n",
      "632000 loss= 5.0461\n",
      "633000 loss= 4.83129\n",
      "634000 loss= 16.3208\n",
      "635000 loss= 7.19379\n",
      "636000 loss= 17.323\n",
      "637000 loss= 4.78896\n",
      "638000 loss= 4.40166\n",
      "639000 loss= 4.44083\n",
      "640000 loss= 4.85348\n",
      "641000 loss= 4.98245\n",
      "642000 loss= 5.42026\n",
      "643000 loss= 4.10919\n",
      "644000 loss= 4.92445\n",
      "645000 loss= 13.4494\n",
      "646000 loss= 4.65033\n",
      "647000 loss= 4.93458\n",
      "648000 loss= 11.0484\n",
      "649000 loss= 10.9256\n",
      "650000 loss= 4.47259\n",
      "651000 loss= 5.08232\n",
      "652000 loss= 4.37459\n",
      "653000 loss= 4.47104\n",
      "654000 loss= 4.74838\n",
      "655000 loss= 4.55395\n",
      "656000 loss= 10.5461\n",
      "657000 loss= 5.12278\n",
      "658000 loss= 8.88686\n",
      "659000 loss= 4.79417\n",
      "660000 loss= 4.73186\n",
      "661000 loss= 4.78083\n",
      "662000 loss= 4.3606\n",
      "663000 loss= 4.12508\n",
      "664000 loss= 5.63048\n",
      "665000 loss= 4.27105\n",
      "666000 loss= 4.88788\n",
      "667000 loss= 4.52356\n",
      "668000 loss= 4.33701\n",
      "669000 loss= 4.94224\n",
      "670000 loss= 5.17326\n",
      "671000 loss= 9.54166\n",
      "672000 loss= 4.58032\n",
      "673000 loss= 4.70405\n",
      "674000 loss= 4.87777\n",
      "675000 loss= 6.02327\n",
      "676000 loss= 4.83335\n",
      "677000 loss= 4.65554\n",
      "678000 loss= 4.68223\n",
      "679000 loss= 4.24604\n",
      "680000 loss= 3.91026\n",
      "681000 loss= 4.82812\n",
      "682000 loss= 5.00321\n",
      "683000 loss= 4.23784\n",
      "684000 loss= 4.19702\n",
      "685000 loss= 8.5351\n",
      "686000 loss= 4.54255\n",
      "687000 loss= 4.61273\n",
      "688000 loss= 4.79387\n",
      "689000 loss= 4.40467\n",
      "690000 loss= 4.1795\n",
      "691000 loss= 8.57166\n",
      "692000 loss= 4.17957\n",
      "693000 loss= 4.70521\n",
      "694000 loss= 4.54628\n",
      "695000 loss= 4.84771\n",
      "696000 loss= 4.7432\n",
      "697000 loss= 4.14897\n",
      "698000 loss= 5.4408\n",
      "699000 loss= 4.45244\n",
      "700000 loss= 5.06117\n",
      "701000 loss= 10.8812\n",
      "702000 loss= 7.10616\n",
      "703000 loss= 9.3068\n",
      "704000 loss= 6.04539\n",
      "705000 loss= 4.80602\n",
      "706000 loss= 8.755\n",
      "707000 loss= 4.94439\n",
      "708000 loss= 10.8239\n",
      "709000 loss= 4.38086\n",
      "710000 loss= 4.52587\n",
      "711000 loss= 4.12722\n",
      "712000 loss= 4.63959\n",
      "713000 loss= 4.49578\n",
      "714000 loss= 4.94676\n",
      "715000 loss= 4.26871\n",
      "716000 loss= 4.82352\n",
      "717000 loss= 7.15074\n",
      "718000 loss= 4.82562\n",
      "719000 loss= 4.66034\n",
      "720000 loss= 4.88177\n",
      "721000 loss= 9.31484\n",
      "722000 loss= 7.12399\n",
      "723000 loss= 9.47702\n",
      "724000 loss= 6.55952\n",
      "725000 loss= 5.28717\n",
      "726000 loss= 4.77754\n",
      "727000 loss= 4.77192\n",
      "728000 loss= 5.26647\n",
      "729000 loss= 4.76911\n",
      "730000 loss= 4.19982\n",
      "731000 loss= 4.79801\n",
      "732000 loss= 4.47776\n",
      "733000 loss= 4.81383\n",
      "734000 loss= 12.6914\n",
      "735000 loss= 4.6328\n",
      "736000 loss= 4.34434\n",
      "737000 loss= 7.45308\n",
      "738000 loss= 4.81182\n",
      "739000 loss= 4.11777\n",
      "740000 loss= 4.31994\n",
      "741000 loss= 4.51419\n",
      "742000 loss= 8.17822\n",
      "743000 loss= 4.93705\n",
      "744000 loss= 5.27462\n",
      "745000 loss= 15.4552\n",
      "746000 loss= 4.33985\n",
      "747000 loss= 5.02672\n",
      "748000 loss= 14.5767\n",
      "749000 loss= 10.2126\n",
      "750000 loss= 5.19563\n",
      "751000 loss= 4.22234\n",
      "752000 loss= 4.92841\n",
      "753000 loss= 9.23629\n",
      "754000 loss= 4.95442\n",
      "755000 loss= 4.3496\n",
      "756000 loss= 4.95827\n",
      "757000 loss= 11.2865\n",
      "758000 loss= 4.33889\n",
      "759000 loss= 7.60495\n",
      "760000 loss= 4.4623\n",
      "761000 loss= 4.94351\n",
      "762000 loss= 4.96262\n",
      "763000 loss= 16.6144\n",
      "764000 loss= 5.10895\n",
      "765000 loss= 4.11424\n",
      "766000 loss= 4.07496\n",
      "767000 loss= 4.83124\n",
      "768000 loss= 17.6343\n",
      "769000 loss= 5.89018\n",
      "770000 loss= 4.57768\n",
      "771000 loss= 4.45324\n",
      "772000 loss= 4.72298\n",
      "773000 loss= 7.3195\n",
      "774000 loss= 8.14989\n",
      "775000 loss= 5.03637\n",
      "776000 loss= 4.8722\n",
      "777000 loss= 4.37535\n",
      "778000 loss= 4.90776\n",
      "779000 loss= 8.32493\n",
      "780000 loss= 5.18238\n",
      "781000 loss= 6.04581\n",
      "782000 loss= 4.37768\n",
      "783000 loss= 5.02012\n",
      "784000 loss= 4.55225\n",
      "785000 loss= 19.054\n",
      "786000 loss= 4.21\n",
      "787000 loss= 4.61126\n",
      "788000 loss= 4.68874\n",
      "789000 loss= 5.04082\n",
      "790000 loss= 4.73458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "791000 loss= 7.48354\n",
      "792000 loss= 4.6634\n",
      "793000 loss= 19.0877\n",
      "794000 loss= 4.87795\n",
      "795000 loss= 5.17018\n",
      "796000 loss= 16.9023\n",
      "797000 loss= 5.21196\n",
      "798000 loss= 5.65979\n",
      "799000 loss= 14.2727\n",
      "800000 loss= 4.86168\n",
      "801000 loss= 4.47149\n",
      "802000 loss= 4.95987\n",
      "803000 loss= 4.92313\n",
      "804000 loss= 7.88829\n",
      "805000 loss= 5.18504\n",
      "806000 loss= 10.3493\n",
      "807000 loss= 4.60149\n",
      "808000 loss= 4.83744\n",
      "809000 loss= 4.62306\n",
      "810000 loss= 4.48364\n",
      "811000 loss= 4.74476\n",
      "812000 loss= 17.5494\n",
      "813000 loss= 4.5536\n",
      "814000 loss= 4.73604\n",
      "815000 loss= 4.66203\n",
      "816000 loss= 8.78923\n",
      "817000 loss= 16.599\n",
      "818000 loss= 10.1033\n",
      "819000 loss= 7.77062\n",
      "820000 loss= 8.89803\n",
      "821000 loss= 4.23283\n",
      "822000 loss= 7.60519\n",
      "823000 loss= 4.35733\n",
      "824000 loss= 6.59965\n",
      "825000 loss= 4.656\n",
      "826000 loss= 4.21586\n",
      "827000 loss= 5.13169\n",
      "828000 loss= 4.40661\n",
      "829000 loss= 8.34948\n",
      "830000 loss= 4.74023\n",
      "831000 loss= 4.8398\n",
      "832000 loss= 4.32539\n",
      "833000 loss= 4.43347\n",
      "834000 loss= 4.19985\n",
      "835000 loss= 4.48017\n",
      "836000 loss= 4.37557\n",
      "837000 loss= 4.44863\n",
      "838000 loss= 4.84516\n",
      "839000 loss= 9.60313\n",
      "840000 loss= 4.81325\n",
      "841000 loss= 4.06239\n",
      "842000 loss= 4.53042\n",
      "843000 loss= 4.59418\n",
      "844000 loss= 17.0647\n",
      "845000 loss= 4.85947\n",
      "846000 loss= 8.23458\n",
      "847000 loss= 4.68073\n",
      "848000 loss= 4.96493\n",
      "849000 loss= 4.93114\n",
      "850000 loss= 7.95346\n",
      "851000 loss= 4.45287\n",
      "852000 loss= 5.05814\n",
      "853000 loss= 4.63563\n",
      "854000 loss= 5.05807\n",
      "855000 loss= 4.23398\n",
      "856000 loss= 4.88652\n",
      "857000 loss= 5.08079\n",
      "858000 loss= 4.60753\n",
      "859000 loss= 4.0139\n",
      "860000 loss= 4.7863\n",
      "861000 loss= 14.2552\n",
      "862000 loss= 16.5455\n",
      "863000 loss= 4.13399\n",
      "864000 loss= 4.35061\n",
      "865000 loss= 5.37692\n",
      "866000 loss= 4.9228\n",
      "867000 loss= 7.09208\n",
      "868000 loss= 4.67246\n",
      "869000 loss= 4.24307\n",
      "870000 loss= 7.16355\n",
      "871000 loss= 5.03508\n",
      "872000 loss= 6.33863\n",
      "873000 loss= 4.7456\n",
      "874000 loss= 4.51764\n",
      "875000 loss= 5.03924\n",
      "876000 loss= 5.35045\n",
      "877000 loss= 7.53733\n",
      "878000 loss= 4.66317\n",
      "879000 loss= 17.6773\n",
      "880000 loss= 4.36089\n",
      "881000 loss= 4.94658\n",
      "882000 loss= 4.47429\n",
      "883000 loss= 4.57286\n",
      "884000 loss= 6.36529\n",
      "885000 loss= 4.68353\n",
      "886000 loss= 4.39961\n",
      "887000 loss= 4.30717\n",
      "888000 loss= 4.33628\n",
      "889000 loss= 4.7908\n",
      "890000 loss= 4.0031\n",
      "891000 loss= 4.39932\n",
      "892000 loss= 4.00704\n",
      "893000 loss= 4.47787\n",
      "894000 loss= 5.11204\n",
      "895000 loss= 4.81737\n",
      "896000 loss= 4.64817\n",
      "897000 loss= 15.7804\n",
      "898000 loss= 3.78019\n",
      "899000 loss= 4.45081\n",
      "900000 loss= 4.6708\n",
      "901000 loss= 4.68139\n",
      "902000 loss= 4.28718\n",
      "903000 loss= 4.35122\n",
      "904000 loss= 4.66176\n",
      "905000 loss= 6.04352\n",
      "906000 loss= 10.9634\n",
      "907000 loss= 4.19507\n",
      "908000 loss= 4.52455\n",
      "909000 loss= 7.11811\n",
      "910000 loss= 9.34468\n",
      "911000 loss= 8.11574\n",
      "912000 loss= 4.81334\n",
      "913000 loss= 5.1117\n",
      "914000 loss= 4.1711\n",
      "915000 loss= 7.01111\n",
      "916000 loss= 4.94398\n",
      "917000 loss= 4.31172\n",
      "918000 loss= 4.41842\n",
      "919000 loss= 4.34184\n",
      "920000 loss= 4.79466\n",
      "921000 loss= 6.54944\n",
      "922000 loss= 4.86335\n",
      "923000 loss= 5.79066\n",
      "924000 loss= 4.09699\n",
      "925000 loss= 4.71201\n",
      "926000 loss= 4.63075\n",
      "927000 loss= 5.07475\n",
      "928000 loss= 4.40597\n",
      "929000 loss= 4.33555\n",
      "930000 loss= 7.81275\n",
      "931000 loss= 5.61363\n",
      "932000 loss= 9.85241\n",
      "933000 loss= 4.18507\n",
      "934000 loss= 4.5251\n",
      "935000 loss= 5.8434\n",
      "936000 loss= 4.39271\n",
      "937000 loss= 4.49214\n",
      "938000 loss= 4.58572\n",
      "939000 loss= 4.35406\n",
      "940000 loss= 4.32213\n",
      "941000 loss= 4.49495\n",
      "942000 loss= 4.87537\n",
      "943000 loss= 29.3918\n",
      "944000 loss= 6.17715\n",
      "945000 loss= 5.06554\n",
      "946000 loss= 5.04988\n",
      "947000 loss= 4.5564\n",
      "948000 loss= 4.44042\n",
      "949000 loss= 5.29083\n",
      "950000 loss= 6.92772\n",
      "951000 loss= 4.53647\n",
      "952000 loss= 4.57568\n",
      "953000 loss= 4.2331\n",
      "954000 loss= 4.27297\n",
      "955000 loss= 4.66486\n",
      "956000 loss= 4.33763\n",
      "957000 loss= 4.6123\n",
      "958000 loss= 4.78666\n",
      "959000 loss= 4.46362\n",
      "960000 loss= 6.60058\n",
      "961000 loss= 4.61767\n",
      "962000 loss= 7.1305\n",
      "963000 loss= 4.21031\n",
      "964000 loss= 4.93154\n",
      "965000 loss= 4.59384\n",
      "966000 loss= 4.73594\n",
      "967000 loss= 8.49872\n",
      "968000 loss= 4.53965\n",
      "969000 loss= 4.72376\n",
      "970000 loss= 4.69617\n",
      "971000 loss= 4.23187\n",
      "972000 loss= 4.23492\n",
      "973000 loss= 4.57883\n",
      "974000 loss= 4.65326\n",
      "975000 loss= 6.19483\n",
      "976000 loss= 4.53984\n",
      "977000 loss= 4.72636\n",
      "978000 loss= 4.42956\n",
      "979000 loss= 4.30752\n",
      "980000 loss= 4.39624\n",
      "981000 loss= 4.34447\n",
      "982000 loss= 4.02387\n",
      "983000 loss= 3.90161\n",
      "984000 loss= 4.29723\n",
      "985000 loss= 8.71314\n",
      "986000 loss= 4.65906\n",
      "987000 loss= 4.56579\n",
      "988000 loss= 5.14825\n",
      "989000 loss= 4.53298\n",
      "990000 loss= 4.3913\n",
      "991000 loss= 4.145\n",
      "992000 loss= 8.84908\n",
      "993000 loss= 6.35284\n",
      "994000 loss= 4.64125\n",
      "995000 loss= 4.85422\n",
      "996000 loss= 4.63764\n",
      "997000 loss= 4.36755\n",
      "998000 loss= 4.49349\n",
      "999000 loss= 5.02404\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "embedding_size = 300  # Dimension of the embedding vector.\n",
    "skip_window = 2  # How many words to consider left and right.\n",
    "num_skip = 2  # How many times to reuse an input to generate a label.\n",
    "num_sampled = 64  # Number of negative examples to sample.\n",
    "restore_sess=0\n",
    "\n",
    "graph=tf.Graph()\n",
    "with graph.as_default():\n",
    "    inputs = tf.placeholder(tf.int32, shape=[batch_size])\n",
    "    labels = tf.placeholder(tf.int32, shape=[batch_size,1])\n",
    "    embeddings = tf.Variable(tf.random_uniform([n_words, embedding_size], -1.0, 1.0))\n",
    "    #embeddings = tf.Variable(final_embeddings)\n",
    "    embed = tf.nn.embedding_lookup(embeddings, inputs)\n",
    "    nce_loss_weights = tf.Variable(tf.truncated_normal([n_words, embedding_size],stddev=1.0 / np.sqrt(embedding_size)))\n",
    "    nce_loss_biases = tf.Variable(tf.zeros([n_words]))\n",
    "    loss = tf.reduce_mean(tf.nn.nce_loss(weights=nce_loss_weights,biases=nce_loss_biases,labels=labels,inputs=embed,\n",
    "                                         num_sampled=num_sampled,num_classes=n_words))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(1.0).minimize(loss)\n",
    "    #optimizer = tf.train.AdamOptimizer().minimize(loss)\n",
    "    norm = tf.sqrt(tf.reduce_sum(tf.square(embeddings), 1, keep_dims=True))\n",
    "    normalized_embeddings = embeddings / norm\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver=tf.train.Saver()\n",
    "\n",
    "steps=1000000\n",
    "config = tf.ConfigProto(\n",
    "        device_count = {'GPU': 0}\n",
    "    )\n",
    "with tf.Session(graph=graph,config=config) as session:\n",
    "    if restore_sess==1:\n",
    "        saver.restore(session,'./ckpt/skipgram_amazon.ckpt')\n",
    "    init.run()\n",
    "    print('Initialized')\n",
    "\n",
    "    average_loss = 0\n",
    "    for step in range(steps):\n",
    "        batch_inputs, batch_labels = generate_batch_seq(batch_size, skip_window,num_skip)\n",
    "        feed_dict = {inputs: batch_inputs, labels: batch_labels}\n",
    "        _, loss_val = session.run(\n",
    "        [optimizer, loss],\n",
    "        feed_dict=feed_dict)\n",
    "        if step%1000==0:\n",
    "            print(step,'loss=',loss_val)\n",
    "            \n",
    "    saver.save(session,'./ckpt/skipgram_amazon.ckpt')\n",
    "    final_embeddings=normalized_embeddings.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.84558760e-02,  -1.65749788e-02,   6.94774389e-02,\n",
       "         1.66705176e-02,   9.36170965e-02,   2.47048289e-02,\n",
       "        -9.49273482e-02,  -1.10419951e-02,  -6.75776675e-02,\n",
       "        -6.54449016e-02,  -1.13923033e-03,  -7.25404024e-02,\n",
       "         1.13724701e-01,  -4.87168394e-02,  -7.93844610e-02,\n",
       "         4.18764576e-02,   4.04779948e-02,   2.11862754e-02,\n",
       "         1.00889988e-01,  -6.11836463e-02,  -3.54630910e-02,\n",
       "         2.43001012e-03,   7.64218019e-03,  -7.71658495e-02,\n",
       "        -5.49962651e-03,  -4.72761840e-02,  -4.50324789e-02,\n",
       "        -2.82826531e-03,  -7.33576789e-02,   1.08757764e-01,\n",
       "        -7.99919963e-02,  -8.49682465e-02,   2.48433631e-02,\n",
       "        -4.57409509e-02,  -5.89199597e-03,  -4.47022244e-02,\n",
       "        -1.14896826e-01,  -1.05048895e-01,  -1.65068191e-02,\n",
       "        -2.51138788e-02,  -5.13973907e-02,  -4.16491590e-02,\n",
       "         4.94319014e-02,   4.05028649e-02,   4.66745943e-02,\n",
       "        -7.11736754e-02,  -5.20588011e-02,  -2.15571541e-02,\n",
       "         3.22021618e-02,  -5.00605926e-02,   1.40114361e-02,\n",
       "        -7.59786293e-02,   1.22854384e-02,   1.35149313e-02,\n",
       "         1.17182858e-01,   1.65754501e-02,  -3.01810559e-02,\n",
       "        -6.72138436e-03,   7.03485310e-02,   1.85519960e-02,\n",
       "         3.69366854e-02,   1.76648553e-02,   7.46219307e-02,\n",
       "         3.79173756e-02,   3.55379693e-02,  -7.40809366e-02,\n",
       "        -9.98673514e-02,   1.02987863e-01,   4.71184403e-02,\n",
       "        -1.54348684e-03,  -8.42969026e-03,  -7.44202593e-03,\n",
       "         1.72069017e-03,  -2.68825702e-02,  -3.32429670e-02,\n",
       "        -7.54393078e-03,  -3.30627598e-02,  -1.13284357e-01,\n",
       "         4.46527861e-02,  -8.95185173e-02,   9.32320952e-02,\n",
       "        -4.25289050e-02,  -1.28788380e-02,   6.71428069e-02,\n",
       "        -5.27203120e-02,  -6.45860136e-02,  -1.16700478e-01,\n",
       "        -6.89396337e-02,   5.86057641e-03,   6.41513020e-02,\n",
       "        -6.15799911e-02,  -2.52608843e-02,  -6.91519305e-02,\n",
       "        -8.41230433e-03,   4.72649112e-02,   1.06955543e-01,\n",
       "         2.85240579e-02,  -6.19776025e-02,   3.78981717e-02,\n",
       "         3.82325277e-02,   3.44129503e-02,  -2.35288013e-02,\n",
       "         5.53899854e-02,  -4.16764654e-02,  -1.78069789e-02,\n",
       "         5.71074598e-02,  -8.66989791e-02,   3.32964435e-02,\n",
       "         7.04945698e-02,  -6.28262684e-02,  -2.74518747e-02,\n",
       "         4.46867347e-02,   3.44339386e-02,  -4.32519801e-02,\n",
       "         1.32061671e-02,   2.11299453e-02,   2.25433335e-02,\n",
       "        -6.80122003e-02,   9.59036946e-02,   1.01253532e-01,\n",
       "         9.15586948e-02,   3.78457159e-02,   6.71883151e-02,\n",
       "         2.09933743e-02,  -4.26814482e-02,   2.07943581e-02,\n",
       "        -6.41124323e-02,   2.70924252e-02,   1.47721274e-02,\n",
       "         4.91901003e-02,  -1.50591098e-02,  -6.32680804e-02,\n",
       "        -4.56364006e-02,   7.50037655e-02,  -6.46767730e-05,\n",
       "         3.05485558e-02,   2.80362852e-02,   3.60481255e-02,\n",
       "         2.50664335e-02,   1.45651614e-02,   1.77639071e-02,\n",
       "         9.92242396e-02,   4.29939441e-02,   3.90185416e-02,\n",
       "         7.22776204e-02,   1.02393351e-01,   8.51138681e-03,\n",
       "        -4.60470133e-02,   4.90627512e-02,   1.03645675e-01,\n",
       "        -2.60476526e-02,  -4.84522618e-02,   8.71795118e-02,\n",
       "        -1.06473401e-01,  -6.24147393e-02,  -2.36329138e-02,\n",
       "        -3.40025984e-02,  -7.22622918e-03,   9.94750531e-04,\n",
       "        -1.28074870e-01,  -1.72678791e-02,  -8.31399933e-02,\n",
       "         8.49013999e-02,   1.04324287e-02,  -3.79050970e-02,\n",
       "        -9.71609261e-03,  -6.08048216e-02,  -8.18976015e-02,\n",
       "         6.29294738e-02,   7.61586949e-02,  -4.04172465e-02,\n",
       "        -6.03841282e-02,   4.48545106e-02,   3.12805064e-02,\n",
       "         7.33196437e-02,   2.37648245e-02,  -1.24615496e-02,\n",
       "         5.72507903e-02,  -2.67987289e-02,   1.18431181e-01,\n",
       "         1.14415430e-01,   2.97664795e-02,  -4.58600335e-02,\n",
       "        -4.39477526e-02,   2.91037634e-02,   7.08282888e-02,\n",
       "         9.99086127e-02,   1.46179479e-02,  -1.61339832e-03,\n",
       "        -6.08445667e-02,  -1.03363837e-03,  -1.43378321e-02,\n",
       "         9.77756903e-02,   1.39753744e-01,   7.69538060e-02,\n",
       "        -1.47079807e-02,  -2.33941730e-02,  -7.60910213e-02,\n",
       "        -1.03091588e-02,   2.93469392e-02,  -5.38131595e-02,\n",
       "        -8.86089280e-02,  -2.05122889e-03,  -6.22142181e-02,\n",
       "         4.19049077e-02,  -8.06754455e-02,  -4.23350632e-02,\n",
       "         2.05803085e-02,  -5.27470000e-02,   1.14901669e-01,\n",
       "        -6.43064231e-02,   8.17189515e-02,  -5.86049035e-02,\n",
       "         5.85224740e-02,  -3.46158701e-03,  -5.70822209e-02,\n",
       "        -8.64625275e-02,   3.72036882e-02,   5.97420149e-02,\n",
       "        -3.76092568e-02,  -6.80668429e-02,  -5.21324016e-02,\n",
       "         2.97141895e-02,  -1.19387701e-01,  -3.31996009e-03,\n",
       "        -8.08480233e-02,  -1.04366373e-02,  -6.22037016e-02,\n",
       "         3.08024734e-02,  -5.86602204e-02,  -2.27129441e-02,\n",
       "         4.33534272e-02,   8.30366686e-02,   5.85248955e-02,\n",
       "         5.56952432e-02,   1.88715803e-03,   2.89800670e-03,\n",
       "        -1.80031247e-02,   6.11444302e-02,   6.89144954e-02,\n",
       "         2.29743179e-02,  -1.04486430e-02,  -3.91887054e-02,\n",
       "        -5.94970956e-02,   3.55293043e-02,   2.14552432e-02,\n",
       "         8.06156918e-02,   3.96607183e-02,   8.32792255e-04,\n",
       "         4.73321490e-02,  -4.81469668e-02,   5.84988156e-03,\n",
       "        -6.33181706e-02,   8.89019817e-02,  -5.59453033e-02,\n",
       "         1.19052697e-02,   1.21347234e-02,   8.62509944e-03,\n",
       "         8.39359034e-03,  -8.59300271e-02,  -3.81147452e-02,\n",
       "         5.47235049e-02,   8.13187957e-02,  -3.49642821e-02,\n",
       "         2.21487172e-02,  -1.26686366e-02,  -1.86149031e-02,\n",
       "        -4.76052519e-03,   3.76946032e-02,  -1.29607655e-02,\n",
       "        -7.67200589e-02,  -6.32320046e-02,  -5.19422721e-03,\n",
       "         4.69690049e-03,   1.24692582e-01,  -3.35211903e-02,\n",
       "        -2.03518886e-02,  -1.28839081e-02,  -4.79279691e-03,\n",
       "        -1.15678847e-01,  -5.88321015e-02,  -4.50464478e-03,\n",
       "         7.66081512e-02,   2.86043119e-02,  -5.14153317e-02,\n",
       "        -8.01914632e-02,   9.83086824e-02,   8.56106728e-02,\n",
       "         5.54198660e-02,   5.13532870e-02,   6.43509207e-04,\n",
       "        -3.21172364e-02,  -9.38845351e-02,   3.70585993e-02,\n",
       "        -1.01484127e-01,   1.14755169e-01,   4.73151170e-02,\n",
       "         6.01738356e-02,   6.77809641e-02,  -3.88995148e-02], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=final_embeddings[word_dict['seven']]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict={v: k for k, v in word_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pylint: disable=g-import-not-at-top\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tsne = TSNE(\n",
    "  perplexity=30, n_components=2, init='pca', n_iter=5000, method='exact')\n",
    "plot_only = 500\n",
    "low_dim_embs = tsne.fit_transform(final_embeddings[:plot_only, :])\n",
    "labels = [reverse_dict[i] for i in range(plot_only)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def plot_with_labels(low_dim_embs, labels, filename):\n",
    "    assert low_dim_embs.shape[0] >= len(labels), 'More labels than embeddings'\n",
    "    plt.figure(figsize=(18, 18))  # in inches\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = low_dim_embs[i, :]\n",
    "        plt.scatter(x, y)\n",
    "        plt.annotate(\n",
    "            label,\n",
    "            xy=(x, y),\n",
    "            xytext=(5, 2),\n",
    "            textcoords='offset points',\n",
    "            ha='right',\n",
    "            va='bottom')\n",
    "\n",
    "    plt.savefig(filename)\n",
    "plot_with_labels(low_dim_embs, labels, 'tsne.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('./data/word2vec_1M_amazon.npz',final_embeddings,word_dict,reverse_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
